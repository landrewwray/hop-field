# -*- coding: utf-8 -*-
"""hop_field_GAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uN_NNqXglQRVnzdHzkp_auq0D2W36BSU
"""

import numpy as np
import scipy as sc

import tensorflow as tf

import glob
import imageio
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL

from tensorflow.keras import layers
import time

import monte_carlo.summarize_mc as smc

mc_data = smc.MonteCarloOutput()
mc_data.load("C:/Users/danie/OneDrive/Documents/GitHub/hop-field/Training Data.p")

# to see the convergence:
mc_data.showEnergiesGood()  # or mc_data.showEnergiesAll() to see all attempted moves

#%%

totalDataSize = 60000
batchSize = 100
dataLength = 20
dataWidth = 10
dataSize = 5

# def makeDummyData (length, width, size, totalDataSize):
#   dummyData = []
#   for i in range (totalDataSize):
#     dummyData += [np.random.rand(length,width,size)]

#   return(dummyData)

# dummyData = makeDummyData(dataLength, dataWidth, dataSize, totalDataSize)


# trainingDataset = tf.data.Dataset.from_tensor_slices(dummyData).shuffle(totalDataSize).batch(batchSize)

# print(np.shape(dummyData[0])
#       )

# input_shape = (60000, 20, 10, 1)
input_shape = (len(mc_data.trainingData.X), len(mc_data.trainingData.X[0]), mc_data.trainingData.X[0][0].size, len(mc_data.trainingData.y))
output_length = 10*5*2 # (10 molecules * 5 bonds * 2 distortions) -- effective bond number will sometimes be lower
x =[mc_data.trainingData.X, len(mc_data.trainingData.y)]

def make_discriminator_model():
    """Notes: momentum for training?  Can/should batch normalization be applied more regularly?

    """
    model = tf.keras.Sequential()
    model.add(layers.Conv1D(20, 3, strides=(1), padding='valid',
                                     input_shape=input_shape[1:]))  # shape --> (60000, 20, 8, 20)
    model.add(layers.LeakyReLU())
    #model.add(layers.Dropout(0.3))

    model.add(layers.Conv1D(20, (3), strides=(1), padding='valid')) # shape --> (60000, 20, 6, 20)
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))

    model.add(layers.Flatten())  # shape --> (60000, 20*6*20, 1) ???
    model.add(layers.Dense(10*6*20))
    model.add(layers.BatchNormalization())  # keep? only useful in the middle?
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))
    
    model.add(layers.Dense(10*6*10))
    model.add(layers.LeakyReLU())
    #model.add(layers.Dropout(0.3))

    model.add(layers.Dense(10*5*2))  # shape --> (60000, 10 molecules * 5 bonds * 2 distortions) -- effective bond number will sometimes be lower

    return model

discriminator = make_discriminator_model()
decision = discriminator(x)

print(decision.shape)

def make_generator_model():

    # Define
    # ***create all-zeros input with input_shape=(5,output_length)

    # num_predictions = 5
    model = tf.keras.Sequential()
    model.add(layers.Dense(20*6*20, use_bias=False, input_shape=(10*5*2,)))  # input_shape=(5,output_length) Generate 5 ideal universal models
    model.add(layers.LeakyReLU())

    #model.add(layers.BatchNormalization())
    
    model.add(layers.Reshape((20,120))) # originally (20,6,20) but the conv may not be able to take that shape
    print(model.output_shape)
    #assert model.output_shape == ( None, num_predictions, 200)  # Note: None is the batch size  (num_predictions, 6, 20)
    
    model.add(layers.Conv1DTranspose(20, (3), strides=(1), input_shape=(20,120)))  # (num_predictions, 10, ???)  # use_bias=False
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())
    print(model.output_shape)
    # assert model.output_shape == ( None, 20, 8, 20)

    model.add(layers.Conv1DTranspose(1, (3), strides=(1)))  # padding='same', use_bias=False
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    print(model.output_shape)

    #assert model.output_shape == ( None, 20, 10, 1)

    # The goal shape for the end of the generator
    #assert model.output_shape == (None, 20, 10, 1)  # (number of terms ~20, curve length ~20, 1) -- one of the 'terms' should represent the orbital energies?
    print(model.output_shape)

    return model

generator = make_generator_model()

noise = tf.random.normal([1,output_length])
print(noise.shape)
generatedMatrix = generator(noise)

print(generatedMatrix.shape)

# This method returns a helper function to compute cross entropy loss
cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, "ckpt")
checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
                                 discriminator_optimizer=discriminator_optimizer,
                                 generator=generator,
                                 discriminator=discriminator)

EPOCHS = 50
noise_dim = 100
num_examples_to_generate = 16

# You will reuse this seed overtime (so it's easier)
# to visualize progress in the animated GIF)
seed = tf.random.normal([num_examples_to_generate, noise_dim])

# Notice the use of `tf.function`
# This annotation causes the function to be "compiled".
# STILL ONLY FOR 2-D IMAGES- NOT 1-D
@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
      generated_images = generator(noise, training=True)

      real_output = discriminator(images, training=True)
      fake_output = discriminator(generated_images, training=True)

      gen_loss = generator_loss(fake_output)
      disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

def train(dataset, epochs):
  for epoch in range(epochs):
    start = time.time()

    for image_batch in dataset:
      train_step(image_batch)

    # Produce images for the GIF as you go
    display.clear_output(wait=True)
    generate_and_save_images(generator,
                             epoch + 1,
                             seed)

    # Save the model every 15 epochs
    if (epoch + 1) % 15 == 0:
      checkpoint.save(file_prefix = checkpoint_prefix)

    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))

  # Generate after the final epoch
  display.clear_output(wait=True)
  generate_and_save_images(generator,
                           epochs,
                           seed)